{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e338bcf6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-30T15:10:47.848192Z",
     "iopub.status.busy": "2022-06-30T15:10:47.847744Z",
     "iopub.status.idle": "2022-06-30T15:10:47.875131Z",
     "shell.execute_reply": "2022-06-30T15:10:47.873933Z"
    },
    "papermill": {
     "duration": 0.039228,
     "end_time": "2022-06-30T15:10:47.878546",
     "exception": false,
     "start_time": "2022-06-30T15:10:47.839318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sp-500-stocks/sp500_stocks.csv\n",
      "/kaggle/input/sp-500-stocks/sp500_companies.csv\n",
      "/kaggle/input/sp-500-stocks/sp500_index.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5ebf3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:10:47.892592Z",
     "iopub.status.busy": "2022-06-30T15:10:47.891845Z",
     "iopub.status.idle": "2022-06-30T15:10:56.217195Z",
     "shell.execute_reply": "2022-06-30T15:10:56.215868Z"
    },
    "papermill": {
     "duration": 8.335479,
     "end_time": "2022-06-30T15:10:56.220225",
     "exception": false,
     "start_time": "2022-06-30T15:10:47.884746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create df for Tesla Stock price since 2019\n",
    "sp500 = pd.read_csv('/kaggle/input/sp-500-stocks/sp500_stocks.csv')\n",
    "stock = sp500[(sp500['Symbol']=='GOOG') & (sp500['Date'].apply(lambda x:int(x.split('-')[0])) >= 2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fec179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:10:56.233198Z",
     "iopub.status.busy": "2022-06-30T15:10:56.232799Z",
     "iopub.status.idle": "2022-06-30T15:10:56.242931Z",
     "shell.execute_reply": "2022-06-30T15:10:56.241614Z"
    },
    "papermill": {
     "duration": 0.019511,
     "end_time": "2022-06-30T15:10:56.245327",
     "exception": false,
     "start_time": "2022-06-30T15:10:56.225816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating np array \n",
    "def data_split(arr,split_ratio):\n",
    "    spt = round(len(arr)*split_ratio)\n",
    "    arr_train = arr[:spt]\n",
    "    arr_valid = arr[spt:]\n",
    "    return arr_train,arr_valid\n",
    "\n",
    "date = stock['Date'].to_numpy()\n",
    "close = stock['Close'].apply(lambda x:x/100).to_numpy()[...,None]\n",
    "split_ratio = 0.7\n",
    "\n",
    "\n",
    "date_train,date_valid = data_split(date,split_ratio)\n",
    "close_train,close_valid = data_split(close,split_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc604ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:10:56.258929Z",
     "iopub.status.busy": "2022-06-30T15:10:56.258484Z",
     "iopub.status.idle": "2022-06-30T15:11:06.002258Z",
     "shell.execute_reply": "2022-06-30T15:11:06.000966Z"
    },
    "papermill": {
     "duration": 9.754162,
     "end_time": "2022-06-30T15:11:06.005106",
     "exception": false,
     "start_time": "2022-06-30T15:10:56.250944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating Tensorflow data set\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "def window(arr,window_size,batch_size,shuffle):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(arr)\n",
    "    dataset = dataset.window(window_size+1,shift=1,drop_remainder = True)\n",
    "    dataset = dataset.flat_map(lambda window:window.batch(window_size+1))\n",
    "    dataset = dataset.map(lambda window:(window[:-1],window[-1]))\n",
    "    dataset = dataset.shuffle(shuffle)\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9e3ea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:11:06.018419Z",
     "iopub.status.busy": "2022-06-30T15:11:06.017734Z",
     "iopub.status.idle": "2022-06-30T15:11:06.179278Z",
     "shell.execute_reply": "2022-06-30T15:11:06.176513Z"
    },
    "papermill": {
     "duration": 0.171602,
     "end_time": "2022-06-30T15:11:06.182254",
     "exception": false,
     "start_time": "2022-06-30T15:11:06.010652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 15:11:06.036472: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "window_size = 40\n",
    "batch_size = 80\n",
    "shuffle_buffer_size = 10000\n",
    "\n",
    "train_data = window(close_train,window_size,batch_size,shuffle_buffer_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9fb9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:11:06.195118Z",
     "iopub.status.busy": "2022-06-30T15:11:06.194703Z",
     "iopub.status.idle": "2022-06-30T15:11:08.328322Z",
     "shell.execute_reply": "2022-06-30T15:11:08.327049Z"
    },
    "papermill": {
     "duration": 2.143716,
     "end_time": "2022-06-30T15:11:08.331534",
     "exception": false,
     "start_time": "2022-06-30T15:11:06.187818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 40, 40)            1640      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 40, 40)            12960     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20)                4880      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=40, kernel_size=40,\n",
    "                      strides=1,\n",
    "                      activation=\"relu\",\n",
    "                      padding='causal',\n",
    "                      input_shape=[window_size,1]),\n",
    "    tf.keras.layers.LSTM(40,return_sequences=True),\n",
    "    tf.keras.layers.LSTM(20),\n",
    "    tf.keras.layers.Dense(20,activation='relu'),\n",
    "    tf.keras.layers.Dense(10,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8db4a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:11:08.345380Z",
     "iopub.status.busy": "2022-06-30T15:11:08.344962Z",
     "iopub.status.idle": "2022-06-30T15:12:58.703352Z",
     "shell.execute_reply": "2022-06-30T15:12:58.702221Z"
    },
    "papermill": {
     "duration": 110.368308,
     "end_time": "2022-06-30T15:12:58.706096",
     "exception": false,
     "start_time": "2022-06-30T15:11:08.337788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 15:11:10.834959: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 79ms/step - loss: 14.6543\n",
      "\n",
      "Learning rate for epoch 1 is 9.999999747378752e-06\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.6286\n",
      "\n",
      "Learning rate for epoch 2 is 1.1220184205740225e-05\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 14.5756\n",
      "\n",
      "Learning rate for epoch 3 is 1.2589253856276628e-05\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.5114\n",
      "\n",
      "Learning rate for epoch 4 is 1.4125375855655875e-05\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 14.4807\n",
      "\n",
      "Learning rate for epoch 5 is 1.5848931070649996e-05\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.4596\n",
      "\n",
      "Learning rate for epoch 6 is 1.778279329300858e-05\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 14.4347\n",
      "\n",
      "Learning rate for epoch 7 is 1.995262391574215e-05\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.4087\n",
      "\n",
      "Learning rate for epoch 8 is 2.238721208414063e-05\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 14.3835\n",
      "\n",
      "Learning rate for epoch 9 is 2.511886486900039e-05\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 14.3614\n",
      "\n",
      "Learning rate for epoch 10 is 2.8183829272165895e-05\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 14.3413\n",
      "\n",
      "Learning rate for epoch 11 is 3.162277789670043e-05\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.3203\n",
      "\n",
      "Learning rate for epoch 12 is 3.548133827280253e-05\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 14.2960\n",
      "\n",
      "Learning rate for epoch 13 is 3.981071859016083e-05\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 14.2684\n",
      "\n",
      "Learning rate for epoch 14 is 4.46683588961605e-05\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.2382\n",
      "\n",
      "Learning rate for epoch 15 is 5.0118724175263196e-05\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.2062\n",
      "\n",
      "Learning rate for epoch 16 is 5.62341338081751e-05\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.1722\n",
      "\n",
      "Learning rate for epoch 17 is 6.30957365501672e-05\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 14.1359\n",
      "\n",
      "Learning rate for epoch 18 is 7.079458009684458e-05\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 14.0980\n",
      "\n",
      "Learning rate for epoch 19 is 7.943282253108919e-05\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 14.0573\n",
      "\n",
      "Learning rate for epoch 20 is 8.912509656511247e-05\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 14.0117\n",
      "\n",
      "Learning rate for epoch 21 is 9.999999747378752e-05\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 13.9603\n",
      "\n",
      "Learning rate for epoch 22 is 0.00011220184387639165\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 13.9018\n",
      "\n",
      "Learning rate for epoch 23 is 0.0001258925476577133\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 13.8345\n",
      "\n",
      "Learning rate for epoch 24 is 0.00014125375309959054\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 13.7577\n",
      "\n",
      "Learning rate for epoch 25 is 0.00015848931798245758\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 13.6687\n",
      "\n",
      "Learning rate for epoch 26 is 0.00017782794020604342\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 13.5622\n",
      "\n",
      "Learning rate for epoch 27 is 0.0001995262282434851\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 13.4331\n",
      "\n",
      "Learning rate for epoch 28 is 0.00022387212084140629\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 13.2760\n",
      "\n",
      "Learning rate for epoch 29 is 0.0002511886414140463\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 13.0784\n",
      "\n",
      "Learning rate for epoch 30 is 0.00028183829272165895\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 12.8235\n",
      "\n",
      "Learning rate for epoch 31 is 0.0003162277571391314\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 12.4847\n",
      "\n",
      "Learning rate for epoch 32 is 0.0003548133827280253\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 12.0169\n",
      "\n",
      "Learning rate for epoch 33 is 0.0003981071640737355\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 11.3368\n",
      "\n",
      "Learning rate for epoch 34 is 0.00044668358168564737\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 10.2917\n",
      "\n",
      "Learning rate for epoch 35 is 0.0005011872272007167\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 8.5660\n",
      "\n",
      "Learning rate for epoch 36 is 0.000562341301701963\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 5.3375\n",
      "\n",
      "Learning rate for epoch 37 is 0.000630957365501672\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.5258\n",
      "\n",
      "Learning rate for epoch 38 is 0.0007079457864165306\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.7993\n",
      "\n",
      "Learning rate for epoch 39 is 0.0007943282253108919\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.3708\n",
      "\n",
      "Learning rate for epoch 40 is 0.0008912509656511247\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 2.3289\n",
      "\n",
      "Learning rate for epoch 41 is 0.0010000000474974513\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.2826\n",
      "\n",
      "Learning rate for epoch 42 is 0.0011220184387639165\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.3128\n",
      "\n",
      "Learning rate for epoch 43 is 0.001258925418369472\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.1316\n",
      "\n",
      "Learning rate for epoch 44 is 0.0014125375309959054\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 2.2881\n",
      "\n",
      "Learning rate for epoch 45 is 0.0015848932089284062\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.8982\n",
      "\n",
      "Learning rate for epoch 46 is 0.0017782794311642647\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.9061\n",
      "\n",
      "Learning rate for epoch 47 is 0.00199526222422719\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.7899\n",
      "\n",
      "Learning rate for epoch 48 is 0.0022387211211025715\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.2063\n",
      "\n",
      "Learning rate for epoch 49 is 0.002511886414140463\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.4469\n",
      "\n",
      "Learning rate for epoch 50 is 0.0028183830436319113\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.3362\n",
      "\n",
      "Learning rate for epoch 51 is 0.003162277629598975\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.4327\n",
      "\n",
      "Learning rate for epoch 52 is 0.003548133885487914\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.3902\n",
      "\n",
      "Learning rate for epoch 53 is 0.003981071524322033\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.4858\n",
      "\n",
      "Learning rate for epoch 54 is 0.004466835875064135\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.3718\n",
      "\n",
      "Learning rate for epoch 55 is 0.005011872388422489\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.3299\n",
      "\n",
      "Learning rate for epoch 56 is 0.005623413249850273\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.3476\n",
      "\n",
      "Learning rate for epoch 57 is 0.0063095735386013985\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.3712\n",
      "\n",
      "Learning rate for epoch 58 is 0.007079457864165306\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.3764\n",
      "\n",
      "Learning rate for epoch 59 is 0.007943281903862953\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.3184\n",
      "\n",
      "Learning rate for epoch 60 is 0.008912509307265282\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.3352\n",
      "\n",
      "Learning rate for epoch 61 is 0.009999999776482582\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.3015\n",
      "\n",
      "Learning rate for epoch 62 is 0.011220184154808521\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.2586\n",
      "\n",
      "Learning rate for epoch 63 is 0.012589254416525364\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.6968\n",
      "\n",
      "Learning rate for epoch 64 is 0.01412537507712841\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.6971\n",
      "\n",
      "Learning rate for epoch 65 is 0.015848932787775993\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.4658\n",
      "\n",
      "Learning rate for epoch 66 is 0.017782794311642647\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.4595\n",
      "\n",
      "Learning rate for epoch 67 is 0.019952623173594475\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 2.5210\n",
      "\n",
      "Learning rate for epoch 68 is 0.02238721214234829\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.6725\n",
      "\n",
      "Learning rate for epoch 69 is 0.025118865072727203\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 2.8426\n",
      "\n",
      "Learning rate for epoch 70 is 0.02818382903933525\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.7006\n",
      "\n",
      "Learning rate for epoch 71 is 0.03162277489900589\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 3.1189\n",
      "\n",
      "Learning rate for epoch 72 is 0.03548133745789528\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 2.6219\n",
      "\n",
      "Learning rate for epoch 73 is 0.03981071710586548\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.4204\n",
      "\n",
      "Learning rate for epoch 74 is 0.04466835781931877\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.6805\n",
      "\n",
      "Learning rate for epoch 75 is 0.05011872202157974\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.6609\n",
      "\n",
      "Learning rate for epoch 76 is 0.05623413249850273\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.5124\n",
      "\n",
      "Learning rate for epoch 77 is 0.06309573352336884\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.3800\n",
      "\n",
      "Learning rate for epoch 78 is 0.07079457491636276\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.4683\n",
      "\n",
      "Learning rate for epoch 79 is 0.07943282276391983\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.7373\n",
      "\n",
      "Learning rate for epoch 80 is 0.08912509679794312\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.5300\n",
      "\n",
      "Learning rate for epoch 81 is 0.10000000149011612\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.7202\n",
      "\n",
      "Learning rate for epoch 82 is 0.11220184713602066\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 2.6234\n",
      "\n",
      "Learning rate for epoch 83 is 0.1258925348520279\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.5207\n",
      "\n",
      "Learning rate for epoch 84 is 0.1412537544965744\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 2.4842\n",
      "\n",
      "Learning rate for epoch 85 is 0.15848931670188904\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.6422\n",
      "\n",
      "Learning rate for epoch 86 is 0.17782793939113617\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.5718\n",
      "\n",
      "Learning rate for epoch 87 is 0.19952623546123505\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.4828\n",
      "\n",
      "Learning rate for epoch 88 is 0.223872110247612\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.7573\n",
      "\n",
      "Learning rate for epoch 89 is 0.25118863582611084\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.6137\n",
      "\n",
      "Learning rate for epoch 90 is 0.2818382978439331\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.4657\n",
      "\n",
      "Learning rate for epoch 91 is 0.3162277638912201\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.6087\n",
      "\n",
      "Learning rate for epoch 92 is 0.3548133969306946\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.8517\n",
      "\n",
      "Learning rate for epoch 93 is 0.3981071710586548\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.6842\n",
      "\n",
      "Learning rate for epoch 94 is 0.4466835856437683\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.8727\n",
      "\n",
      "Learning rate for epoch 95 is 0.5011872053146362\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.5031\n",
      "\n",
      "Learning rate for epoch 96 is 0.5623413324356079\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.4697\n",
      "\n",
      "Learning rate for epoch 97 is 0.6309573650360107\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.3739\n",
      "\n",
      "Learning rate for epoch 98 is 0.7079457640647888\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.3622\n",
      "\n",
      "Learning rate for epoch 99 is 0.7943282127380371\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 2.3866\n",
      "\n",
      "Learning rate for epoch 100 is 0.8912509083747864\n"
     ]
    }
   ],
   "source": [
    "init_weights = model.get_weights()\n",
    "# Set the learning rate scheduler\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-5 * 10**(epoch / 20))\n",
    "\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(        epoch + 1, model.optimizer.lr.numpy()))\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, epochs=100, callbacks=[lr_schedule,PrintLR()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173a4d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:12:58.859851Z",
     "iopub.status.busy": "2022-06-30T15:12:58.858326Z",
     "iopub.status.idle": "2022-06-30T15:12:59.697238Z",
     "shell.execute_reply": "2022-06-30T15:12:59.695999Z"
    },
    "papermill": {
     "duration": 0.919436,
     "end_time": "2022-06-30T15:12:59.700348",
     "exception": false,
     "start_time": "2022-06-30T15:12:58.780912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-05, 10.0, 1.0, 15.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the learning rate array\n",
    "lrs = 1e-5 * (10 ** (np.arange(100) / 20))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot the loss in log scale\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n",
    "\n",
    "# Increase the tickmarks size\n",
    "plt.tick_params('both', length=10, width=1, which='both')\n",
    "\n",
    "# Set the plot boundaries\n",
    "plt.axis([1e-5, 10, 1, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335d7acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:12:59.853392Z",
     "iopub.status.busy": "2022-06-30T15:12:59.852675Z",
     "iopub.status.idle": "2022-06-30T15:12:59.879344Z",
     "shell.execute_reply": "2022-06-30T15:12:59.877977Z"
    },
    "papermill": {
     "duration": 0.106574,
     "end_time": "2022-06-30T15:12:59.882171",
     "exception": false,
     "start_time": "2022-06-30T15:12:59.775597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.set_weights(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde7aeb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:13:00.040149Z",
     "iopub.status.busy": "2022-06-30T15:13:00.039747Z",
     "iopub.status.idle": "2022-06-30T15:13:00.054045Z",
     "shell.execute_reply": "2022-06-30T15:13:00.052776Z"
    },
    "papermill": {
     "duration": 0.097952,
     "end_time": "2022-06-30T15:13:00.056720",
     "exception": false,
     "start_time": "2022-06-30T15:12:59.958768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate=0.004\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate,momentum=0.9)\n",
    "loss=tf.keras.losses.Huber()\n",
    "\n",
    "model.compile(optimizer=optimizer,loss=loss, metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce3cd5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:13:00.208787Z",
     "iopub.status.busy": "2022-06-30T15:13:00.208231Z",
     "iopub.status.idle": "2022-06-30T15:14:31.511485Z",
     "shell.execute_reply": "2022-06-30T15:14:31.510454Z"
    },
    "papermill": {
     "duration": 91.383264,
     "end_time": "2022-06-30T15:14:31.515349",
     "exception": false,
     "start_time": "2022-06-30T15:13:00.132085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 79ms/step - loss: 14.2909 - mae: 14.7909\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 12.7059 - mae: 13.2059\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 6.2083 - mae: 6.6952\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 3.2376 - mae: 3.7026\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.3751 - mae: 2.8330\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.4551 - mae: 2.9185\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.3862 - mae: 2.8423\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.2258 - mae: 2.6871\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.0161 - mae: 2.4631\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.9605 - mae: 2.4148\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.1691 - mae: 2.6303\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.2893 - mae: 2.7458\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 2.1135 - mae: 2.5626\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.8995 - mae: 2.3478\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.7445 - mae: 2.1883\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7458 - mae: 2.1974\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.5785 - mae: 2.0179\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7062 - mae: 2.1573\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.5112 - mae: 1.9516\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.0730 - mae: 1.5056\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.6732 - mae: 3.1300\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.5089 - mae: 2.9802\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.2059 - mae: 2.6598\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.1408 - mae: 2.5774\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 1.9448 - mae: 2.3980\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.8090 - mae: 2.2507\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.5478 - mae: 1.9771\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.9563 - mae: 2.4096\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.2269 - mae: 2.6831\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.3024 - mae: 2.7645\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.1492 - mae: 2.6003\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.2729 - mae: 2.7284\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 1.7789 - mae: 2.2173\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.5360 - mae: 1.9807\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.3721 - mae: 2.8452\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.3195 - mae: 2.7736\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 1.6288 - mae: 2.0707\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.0792 - mae: 2.5472\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2902 - mae: 1.7112\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.4274 - mae: 1.8630\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.3893 - mae: 2.8433\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.5131 - mae: 2.9778\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 2.4415 - mae: 2.9035\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.3599 - mae: 2.8197\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.3789 - mae: 2.8424\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.3418 - mae: 2.7956\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.3479 - mae: 2.8079\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 2.3837 - mae: 2.8512\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 2.4844 - mae: 2.9519\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 2.3748 - mae: 2.8292\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 2.3236 - mae: 2.7855\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.2663 - mae: 2.7247\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 2.2297 - mae: 2.6802\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 2.4245 - mae: 2.8830\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.3865 - mae: 2.8474\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.3582 - mae: 2.8129\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.3807 - mae: 2.8441\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.4162 - mae: 2.8752\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.3422 - mae: 2.7999\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.4041 - mae: 2.8636\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.3553 - mae: 2.8152\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.3461 - mae: 2.8101\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 2.3344 - mae: 2.7926\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.3435 - mae: 2.8027\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.4693 - mae: 2.9314\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.3821 - mae: 2.8444\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.3870 - mae: 2.8396\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.4713 - mae: 2.9318\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.5318 - mae: 2.9903\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.4817 - mae: 2.9436\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.3636 - mae: 2.8180\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 2.3609 - mae: 2.8246\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.3594 - mae: 2.8159\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.3755 - mae: 2.8393\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 2.3643 - mae: 2.8289\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 2.3525 - mae: 2.8080\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 2.4039 - mae: 2.8679\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.3521 - mae: 2.8143\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.3592 - mae: 2.8217\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 2.3907 - mae: 2.8418\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.3807 - mae: 2.8354\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.3509 - mae: 2.8146\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 2.3621 - mae: 2.8224\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 2.3698 - mae: 2.8282\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 2.3547 - mae: 2.8201\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.3475 - mae: 2.8087\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.3764 - mae: 2.8395\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.3685 - mae: 2.8301\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.3465 - mae: 2.8101\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 2.3393 - mae: 2.8006\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.3392 - mae: 2.8002\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.3269 - mae: 2.7833\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 2.3336 - mae: 2.7949\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.3243 - mae: 2.7813\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.3122 - mae: 2.7746\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.4188 - mae: 2.8798\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.3288 - mae: 2.7901\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.3355 - mae: 2.7897\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.1340 - mae: 2.5905\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 2.3355 - mae: 2.7889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84bb49f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:14:31.823321Z",
     "iopub.status.busy": "2022-06-30T15:14:31.822926Z",
     "iopub.status.idle": "2022-06-30T15:14:32.133290Z",
     "shell.execute_reply": "2022-06-30T15:14:32.131471Z"
    },
    "papermill": {
     "duration": 0.461684,
     "end_time": "2022-06-30T15:14:32.135505",
     "exception": true,
     "start_time": "2022-06-30T15:14:31.673821",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/629306943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Plot mae and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m plot_series(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_series' is not defined"
     ]
    }
   ],
   "source": [
    "# Get mae and loss from history log\n",
    "mae=history.history['mae']\n",
    "loss=history.history['loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs=range(len(loss)) \n",
    "\n",
    "# Plot mae and loss\n",
    "plot_series(\n",
    "    x=epochs, \n",
    "    y=(mae, loss), \n",
    "    title='MAE and Loss', \n",
    "    xlabel='MAE',\n",
    "    ylabel='Loss',\n",
    "    legend=['MAE', 'Loss']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d2ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T14:33:53.178985Z",
     "iopub.status.busy": "2022-06-30T14:33:53.177974Z",
     "iopub.status.idle": "2022-06-30T14:33:53.186423Z",
     "shell.execute_reply": "2022-06-30T14:33:53.185678Z",
     "shell.execute_reply.started": "2022-06-30T14:33:53.178944Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_series(x, y, format=\"-\", start=0, end=None, \n",
    "                title=None, xlabel=None, ylabel=None, legend=None ):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      x (array of int) - contains values for the x-axis\n",
    "      y (array of int or tuple of arrays) - contains the values for the y-axis\n",
    "      format (string) - line style when plotting the graph\n",
    "      start (int) - first time step to plot\n",
    "      end (int) - last time step to plot\n",
    "      title (string) - title of the plot\n",
    "      xlabel (string) - label for the x-axis\n",
    "      ylabel (string) - label for the y-axis\n",
    "      legend (list of strings) - legend for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Check if there are more than two series to plot\n",
    "    if type(y) is tuple:\n",
    "\n",
    "      # Loop over the y elements\n",
    "      for y_curr in y:\n",
    "\n",
    "        # Plot the x and current y values\n",
    "        plt.plot(x[start:end], y_curr[start:end], format)\n",
    "\n",
    "    else:\n",
    "      # Plot the x and y values\n",
    "      plt.plot(x[start:end], y[start:end], format)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(xlabel)\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    # Set the legend\n",
    "    if legend:\n",
    "      plt.legend(legend)\n",
    "\n",
    "    # Set the title\n",
    "    plt.title(title)\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c9471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:07:42.270930Z",
     "iopub.status.busy": "2022-06-30T15:07:42.270551Z",
     "iopub.status.idle": "2022-06-30T15:07:45.133309Z",
     "shell.execute_reply": "2022-06-30T15:07:45.132092Z",
     "shell.execute_reply.started": "2022-06-30T15:07:42.270899Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_forecast(model,series,window_size,batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size,shift=1,drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda w:w.batch(window_size))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(dataset)\n",
    "    return forecast\n",
    "\n",
    "forecast_close = close[round(len(close)*split_ratio)-window_size:-1]\n",
    "\n",
    "forecast = model_forecast(model,forecast_close,window_size,batch_size)\n",
    "\n",
    "results = forecast.squeeze()\n",
    "\n",
    "plot_series(date_valid, (close_valid, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1d53a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T15:08:33.950996Z",
     "iopub.status.busy": "2022-06-30T15:08:33.950582Z",
     "iopub.status.idle": "2022-06-30T15:08:33.961644Z",
     "shell.execute_reply": "2022-06-30T15:08:33.960192Z",
     "shell.execute_reply.started": "2022-06-30T15:08:33.950959Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tf.keras.metrics.mean_absolute_error(close_valid, results).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc9c93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 238.971352,
   "end_time": "2022-06-30T15:14:35.480011",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-30T15:10:36.508659",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
